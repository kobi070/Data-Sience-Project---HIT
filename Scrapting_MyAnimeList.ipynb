{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing relevent lib ###\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import scipy as sc\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Site's url's ###\n",
    "mal_genre_front_page = 'https://myanimelist.net/anime'\n",
    "top_anime_url = 'https://myanimelist.net/topanime.php'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '\"/Users/Kobi/Downloads/chromedriver.exe\"'\n",
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All Genres in Site ###\n",
    "genre_dict = {\n",
    "    'Action': '1',\n",
    "    'Adventure':'2',\n",
    "    'Cars':'3',\n",
    "    'Comedy':'4',\n",
    "    'Dementia':'5',\n",
    "    'Demons':'6',\n",
    "    'Drama':'8',\n",
    "    'Ecchi':'9',\n",
    "    'Fantasy':'10',\n",
    "    'Game':'11',\n",
    "    'Historical':'13',\n",
    "    'Horror':'14',\n",
    "    'Kids':'15',\n",
    "    'Harem':'35',\n",
    "    'Josei':'43'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get all genre links to scrapt information of each genre Anime in myAnimeList ###\n",
    "def get_all_genre_links(site_url):\n",
    "    genre_url = []\n",
    "    for i in genre_dict:\n",
    "        genre_url.append(site_url + genre_dict[i]+ '/'+i)\n",
    "    return genre_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get all top anime links\n",
    "def get_all_top_links(site_url):\n",
    "    all_top_urls = []\n",
    "    for i in range(50,200,50):\n",
    "        all_top_urls.append(site_url+'?limit='+str(i))\n",
    "    return all_top_urls\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "### All genre Links list ###\n",
    "mal_genre_links = get_all_genre_links(mal_genre_front_page)\n",
    "### All Top 0-19,000 Anime's in mal URL ###\n",
    "top_anime_list = get_all_top_links(top_anime_url)\n",
    "\n",
    "\n",
    "#print(mal_genre_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load a soup Object ###\n",
    "def load_soup_obj(html):\n",
    "    html_get = requests.get(html).text\n",
    "    soup = BeautifulSoup(html_get,'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Engline The Episodes ###\n",
    "def parse_episodes(listt):\n",
    "    result = []\n",
    "    for i in listt[:2]:\n",
    "        r = i.strip()\n",
    "        result.append(r)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Take Top Anime col and transfet to DataFrame ###\n",
    "def top_anime_to_df(row_con):\n",
    "    top_anime = []\n",
    "    top_anime_Rank = []\n",
    "    top_anime_Title = []\n",
    "    top_anime_Rating = []\n",
    "    top_anime_URL = []\n",
    "    top_anime_Image_URL = []\n",
    "    top_anime_Episodes = []\n",
    "    top_anime_Dates = []\n",
    "\n",
    "    for row in row_content:\n",
    "        episode = parse_episodes(row.find('div', class_ = \"information di-ib mt4\").text.strip().split('\\n'))\n",
    "        top_anime_URL.append(row.find('td', class_= \"title al va-t word-break\").find('a')['href'])\n",
    "        top_anime_Rank.append(row.find('td', class_ = \"rank ac\").find('span').text)\n",
    "        top_anime_Title.append(row.find('div', class_=\"di-ib clearfix\").find('a').text)\n",
    "        top_anime_Rating.append(row.find('td', class_=\"score ac fs14\").find('span').text)\n",
    "        top_anime_Image_URL.append(row.find('td', class_ ='title al va-t word-break').find('img')['data-src'])\n",
    "        top_anime_Episodes = episode[0]\n",
    "        top_anime_Dates = episode[1]\n",
    "    \n",
    "        top_anime_df = pd.DataFrame({'Rank':top_anime_Rank,'Title':top_anime_Title,\n",
    "                                     'Rating':top_anime_Rating,'Image_URL':top_anime_Image_URL\n",
    "                                     ,'Episodes':top_anime_Episodes,'Dates':top_anime_Dates,\n",
    "                                        'URL':top_anime_URL})\n",
    "    \n",
    "    return top_anime_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load top anime sites to transfer to DataFrame ###\n",
    "def load_top_anime_html(site):    \n",
    "    ### Load the soup object trough load_soup_obj() ###\n",
    "    soup = load_soup_obj(site)\n",
    "    soup.title.text.strip()\n",
    "    ### find all Rank, Title, Rating, Date of Release, Episodes, Image_Url ###\n",
    "    headers_mal = soup.find('tr', class_ = 'table-header')\n",
    "    ### extract Rank, Title, Rating, Date of Release, Episodes, Image_Url from the given HTML ###\n",
    "    row_content = soup.find_all('tr', {'class' : \"ranking-list\"})\n",
    "    return row_content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-493-d54040742eba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mdf_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhtml_to_lists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdf_merged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[1;32m---> 74\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     ):\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[0m_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m         \u001b[0m_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_left\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_validate_operand\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   2059\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m   2062\u001b[0m             \u001b[1;34mf\"Can only merge Series or DataFrame objects, a {type(obj)} was passed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m         )\n",
      "\u001b[1;31mTypeError\u001b[0m: Can only merge Series or DataFrame objects, a <class 'NoneType'> was passed"
     ]
    }
   ],
   "source": [
    "\n",
    "for i,_ in enumerate(top_anime_list):\n",
    "    html = load_top_anime_html(_)\n",
    "    res = html_to_lists(html)\n",
    "    if (i>=1):\n",
    "        df_new = html_to_lists(html[i])\n",
    "        df_merged = pd.merge(res,df_new)\n",
    "    \n",
    "\n",
    "#res = load_top_anime(top_anime_list[1])\n",
    "#print(top_anime_list[1])\n",
    "#merged_df = pd.merge(top_anime_df_2,res,on=['Rank', 'Title', 'Rating', 'Image_URL', 'Episodes', 'Dates', 'URL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the soup object trough load_soup_obj() ###\n",
    "soup = load_soup_obj('https://myanimelist.net/topanime.php?limit=100')\n",
    "soup.title.text.strip()\n",
    "### find all Rank, Title, Rating, Date of Release, Episodes, Image_Url ###\n",
    "headers_mal = soup.find('tr', class_ = 'table-header')\n",
    "### extract Rank, Title, Rating, Date of Release, Episodes, Image_Url from the given HTML ###\n",
    "row_content = soup.find_all('tr', {'class' : \"ranking-list\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Rank       50 non-null     object\n",
      " 1   Title      50 non-null     object\n",
      " 2   Rating     50 non-null     object\n",
      " 3   Image_URL  50 non-null     object\n",
      " 4   Episodes   50 non-null     object\n",
      " 5   Dates      50 non-null     object\n",
      " 6   URL        50 non-null     object\n",
      "dtypes: object(7)\n",
      "memory usage: 2.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50, 7)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_anime = []\n",
    "top_anime_Rank = []\n",
    "top_anime_Title = []\n",
    "top_anime_Rating = []\n",
    "top_anime_URL = []\n",
    "top_anime_Image_URL = []\n",
    "top_anime_Episodes = []\n",
    "top_anime_Dates = []\n",
    "\n",
    "for row in row_content:\n",
    "    episode = parse_episodes(row.find('div', class_ = \"information di-ib mt4\").text.strip().split('\\n'))\n",
    "    \n",
    "    top_anime_URL.append(row.find('td', class_= \"title al va-t word-break\").find('a')['href'])\n",
    "    top_anime_Rank.append(row.find('td', class_ = \"rank ac\").find('span').text)\n",
    "    top_anime_Title.append(row.find('div', class_=\"di-ib clearfix\").find('a').text)\n",
    "    top_anime_Rating.append(row.find('td', class_=\"score ac fs14\").find('span').text)\n",
    "    top_anime_Image_URL.append(row.find('td', class_ ='title al va-t word-break').find('img')['data-src'])\n",
    "    top_anime_Episodes = episode[0]\n",
    "    top_anime_Dates = episode[1]\n",
    "    \n",
    "top_anime_df = pd.DataFrame({'Rank':top_anime_Rank,'Title':top_anime_Title,\n",
    "                             'Rating':top_anime_Rating,'Image_URL':top_anime_Image_URL\n",
    "                             ,'Episodes':top_anime_Episodes,'Dates':top_anime_Dates,\n",
    "                            'URL':top_anime_URL})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Rank       50 non-null     object\n",
      " 1   Title      50 non-null     object\n",
      " 2   Rating     50 non-null     object\n",
      " 3   Image_URL  50 non-null     object\n",
      " 4   Episodes   50 non-null     object\n",
      " 5   Dates      50 non-null     object\n",
      " 6   URL        50 non-null     object\n",
      "dtypes: object(7)\n",
      "memory usage: 2.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Rank', 'Title', 'Rating', 'Image_URL', 'Episodes', 'Dates', 'URL'], dtype='object')"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_anime_df.info()\n",
    "top_anime_df.shape\n",
    "\n",
    "top_anime_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
